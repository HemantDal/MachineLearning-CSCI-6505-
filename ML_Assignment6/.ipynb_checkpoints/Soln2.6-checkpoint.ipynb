{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_rows(arr,rows):\n",
    "    np.random.shuffle(arr[rows[0]:rows[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>2 CNN Begins here</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.72\n",
      "step 200, training accuracy 0.72\n",
      "step 300, training accuracy 0.82\n",
      "step 400, training accuracy 0.82\n",
      "step 500, training accuracy 0.88\n",
      "step 600, training accuracy 0.86\n",
      "step 700, training accuracy 0.92\n",
      "step 800, training accuracy 0.86\n",
      "step 900, training accuracy 0.9\n",
      "step 1000, training accuracy 0.84\n",
      "step 1100, training accuracy 0.86\n",
      "step 1200, training accuracy 0.78\n",
      "step 1300, training accuracy 0.86\n",
      "step 1400, training accuracy 0.8\n",
      "step 1500, training accuracy 0.82\n",
      "step 1600, training accuracy 0.78\n",
      "step 1700, training accuracy 0.84\n",
      "step 1800, training accuracy 0.84\n",
      "step 1900, training accuracy 0.84\n",
      "step 2000, training accuracy 0.86\n",
      "step 2100, training accuracy 0.74\n",
      "test accuracy 0.92\n",
      "test accuracy 0.96\n",
      "test accuracy 0.98\n",
      "test accuracy 1\n",
      "test accuracy 0.94\n",
      "test accuracy 0.96\n",
      "test accuracy 0.94\n",
      "test accuracy 0.96\n",
      "test accuracy 0.96\n",
      "test accuracy 1\n",
      "test accuracy 0.98\n",
      "test accuracy 1\n",
      "test accuracy 0.94\n",
      "test accuracy 0.96\n",
      "test accuracy 0.94\n",
      "test accuracy 0.98\n",
      "test accuracy 0.94\n",
      "test accuracy 0.96\n",
      "test accuracy 0.96\n",
      "test accuracy 0.92\n",
      "test accuracy 0.94\n",
      "test accuracy 1\n",
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.62\n",
      "step 200, training accuracy 0.68\n",
      "step 300, training accuracy 0.52\n",
      "step 400, training accuracy 0.62\n",
      "step 500, training accuracy 0.68\n",
      "step 600, training accuracy 0.52\n",
      "step 700, training accuracy 0.66\n",
      "step 800, training accuracy 0.64\n",
      "step 900, training accuracy 0.62\n",
      "step 1000, training accuracy 0.64\n",
      "step 1100, training accuracy 0.64\n",
      "step 1200, training accuracy 0.46\n",
      "step 1300, training accuracy 0.6\n",
      "step 1400, training accuracy 0.58\n",
      "step 1500, training accuracy 0.5\n",
      "step 1600, training accuracy 0.5\n",
      "step 1700, training accuracy 0.56\n",
      "step 1800, training accuracy 0.5\n",
      "step 1900, training accuracy 0.64\n",
      "step 2000, training accuracy 0.62\n",
      "step 2100, training accuracy 0.44\n",
      "test accuracy 0.98\n",
      "test accuracy 0.98\n",
      "test accuracy 0.96\n",
      "test accuracy 0.92\n",
      "test accuracy 1\n",
      "test accuracy 0.94\n",
      "test accuracy 0.98\n",
      "test accuracy 0.94\n",
      "test accuracy 0.98\n",
      "test accuracy 0.9\n",
      "test accuracy 1\n",
      "test accuracy 0.92\n",
      "test accuracy 0.98\n",
      "test accuracy 0.92\n",
      "test accuracy 0.94\n",
      "test accuracy 0.92\n",
      "test accuracy 0.96\n",
      "test accuracy 0.9\n",
      "test accuracy 0.98\n",
      "test accuracy 0.94\n",
      "test accuracy 0.98\n",
      "test accuracy 0.98\n",
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.2\n",
      "step 200, training accuracy 0.24\n",
      "step 300, training accuracy 0.28\n",
      "step 400, training accuracy 0.2\n",
      "step 500, training accuracy 0.24\n",
      "step 600, training accuracy 0.28\n",
      "step 700, training accuracy 0.34\n",
      "step 800, training accuracy 0.26\n",
      "step 900, training accuracy 0.34\n",
      "step 1000, training accuracy 0.28\n",
      "step 1100, training accuracy 0.2\n",
      "step 1200, training accuracy 0.22\n",
      "step 1300, training accuracy 0.1\n",
      "step 1400, training accuracy 0.32\n",
      "step 1500, training accuracy 0.14\n",
      "step 1600, training accuracy 0.24\n",
      "step 1700, training accuracy 0.18\n",
      "step 1800, training accuracy 0.34\n",
      "step 1900, training accuracy 0.14\n",
      "step 2000, training accuracy 0.14\n",
      "step 2100, training accuracy 0.18\n",
      "test accuracy 0.78\n",
      "test accuracy 0.86\n",
      "test accuracy 0.84\n",
      "test accuracy 0.8\n",
      "test accuracy 0.82\n",
      "test accuracy 0.74\n",
      "test accuracy 0.8\n",
      "test accuracy 0.7\n",
      "test accuracy 0.78\n",
      "test accuracy 0.84\n",
      "test accuracy 0.86\n",
      "test accuracy 0.76\n",
      "test accuracy 0.78\n",
      "test accuracy 0.92\n",
      "test accuracy 0.88\n",
      "test accuracy 0.84\n",
      "test accuracy 0.76\n",
      "test accuracy 0.84\n",
      "test accuracy 0.78\n",
      "test accuracy 0.92\n",
      "test accuracy 0.88\n",
      "test accuracy 0.84\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.26\n",
      "step 200, training accuracy 0.2\n",
      "step 300, training accuracy 0.2\n",
      "step 400, training accuracy 0.1\n",
      "step 500, training accuracy 0.14\n",
      "step 600, training accuracy 0.1\n",
      "step 700, training accuracy 0.1\n",
      "step 800, training accuracy 0.04\n",
      "step 900, training accuracy 0.1\n",
      "step 1000, training accuracy 0.04\n",
      "step 1100, training accuracy 0.08\n",
      "step 1200, training accuracy 0.14\n",
      "step 1300, training accuracy 0.1\n",
      "step 1400, training accuracy 0.12\n",
      "step 1500, training accuracy 0.2\n",
      "step 1600, training accuracy 0.1\n",
      "step 1700, training accuracy 0.14\n",
      "step 1800, training accuracy 0.1\n",
      "step 1900, training accuracy 0.12\n",
      "step 2000, training accuracy 0.12\n",
      "step 2100, training accuracy 0.04\n",
      "test accuracy 0.2\n",
      "test accuracy 0.24\n",
      "test accuracy 0.2\n",
      "test accuracy 0.18\n",
      "test accuracy 0.24\n",
      "test accuracy 0.22\n",
      "test accuracy 0.16\n",
      "test accuracy 0.2\n",
      "test accuracy 0.2\n",
      "test accuracy 0.18\n",
      "test accuracy 0.18\n",
      "test accuracy 0.2\n",
      "test accuracy 0.22\n",
      "test accuracy 0.16\n",
      "test accuracy 0.16\n",
      "test accuracy 0.14\n",
      "test accuracy 0.22\n",
      "test accuracy 0.18\n",
      "test accuracy 0.18\n",
      "test accuracy 0.26\n",
      "test accuracy 0.2\n",
      "test accuracy 0.16\n",
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.12\n",
      "step 200, training accuracy 0.12\n",
      "step 300, training accuracy 0.16\n",
      "step 400, training accuracy 0.1\n",
      "step 500, training accuracy 0.16\n",
      "step 600, training accuracy 0.14\n",
      "step 700, training accuracy 0.16\n",
      "step 800, training accuracy 0.14\n",
      "step 900, training accuracy 0.06\n",
      "step 1000, training accuracy 0.02\n",
      "step 1100, training accuracy 0.04\n",
      "step 1200, training accuracy 0.04\n",
      "step 1300, training accuracy 0.14\n",
      "step 1400, training accuracy 0.06\n",
      "step 1500, training accuracy 0.08\n",
      "step 1600, training accuracy 0.16\n",
      "step 1700, training accuracy 0.08\n",
      "step 1800, training accuracy 0.08\n",
      "step 1900, training accuracy 0.1\n",
      "step 2000, training accuracy 0.14\n",
      "step 2100, training accuracy 0.06\n",
      "test accuracy 0.06\n",
      "test accuracy 0.08\n",
      "test accuracy 0.06\n",
      "test accuracy 0.16\n",
      "test accuracy 0.1\n",
      "test accuracy 0.16\n",
      "test accuracy 0.16\n",
      "test accuracy 0.08\n",
      "test accuracy 0.14\n",
      "test accuracy 0.12\n",
      "test accuracy 0.2\n",
      "test accuracy 0.14\n",
      "test accuracy 0.14\n",
      "test accuracy 0.2\n",
      "test accuracy 0.1\n",
      "test accuracy 0.18\n",
      "test accuracy 0.1\n",
      "test accuracy 0.14\n",
      "test accuracy 0.18\n",
      "test accuracy 0.22\n",
      "test accuracy 0.16\n",
      "test accuracy 0.08\n"
     ]
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "arrTrain10 = np.ndarray((22,1), dtype = float)\n",
    "arrTrain25 = np.ndarray((22,1), dtype = float)\n",
    "arrTrain50 = np.ndarray((22,1), dtype = float)\n",
    "arrTrain75 = np.ndarray((22,1), dtype = float)\n",
    "arrTrain100 = np.ndarray((22,1), dtype = float)\n",
    "\n",
    "arrTest10 = np.ndarray((22,1), dtype = float)\n",
    "arrTest25 = np.ndarray((22,1), dtype = float)\n",
    "arrTest50 = np.ndarray((22,1), dtype = float)\n",
    "arrTest75 = np.ndarray((22,1), dtype = float)\n",
    "arrTest100 = np.ndarray((22,1), dtype = float)\n",
    "\n",
    "count = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #10% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        shuffle_rows(batch[1], [0,5])\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy10 = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            arrTrain10[count] = train_accuracy10\n",
    "            count+=1\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy10))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    count = 0 \n",
    "    # 10% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        #shuffle_rows(batch[1], [0,5])\n",
    "        if i % 100 == 0:\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('test accuracy %g' % test_accuracy)\n",
    "            arrTest10[count] = test_accuracy\n",
    "            count+=1\n",
    "    sess.close()        \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count = 0\n",
    "    #25% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        shuffle_rows(batch[1], [0,12])\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy25 = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            arrTrain25[count] = train_accuracy25\n",
    "            count+=1\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy25))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "    count = 0        \n",
    "    # 25% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        #shuffle_rows(batch[1], [0,37])\n",
    "        if i % 100 == 0:\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('test accuracy %g' % test_accuracy)\n",
    "            arrTest25[count] = test_accuracy\n",
    "            count+=1   \n",
    "    sess.close()\n",
    "    \n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count = 0 \n",
    "    #50% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        shuffle_rows(batch[1], [0,25])\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy50 = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            arrTrain50[count] = train_accuracy50\n",
    "            count+=1\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy50))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "    count = 0        \n",
    "    # 50% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        #shuffle_rows(batch[1], [0,37])\n",
    "        if i % 100 == 0:\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('test accuracy %g' % test_accuracy)\n",
    "            arrTest50[count] = test_accuracy\n",
    "            count+=1 \n",
    "    sess.close()        \n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count = 0 \n",
    "    #75% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        shuffle_rows(batch[1], [0,37])\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy75 = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            arrTrain75[count] = train_accuracy75\n",
    "            count+=1\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy75))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})  \n",
    "        \n",
    "    count = 0        \n",
    "    # 75% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        #shuffle_rows(batch[1], [0,37])\n",
    "        if i % 100 == 0:\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('test accuracy %g' % test_accuracy)\n",
    "            arrTest75[count] = test_accuracy\n",
    "            count+=1 \n",
    "    sess.close()        \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    count = 0 \n",
    "    #100% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        shuffle_rows(batch[1], [0,50])\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy100 = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            arrTrain100[count] = train_accuracy100\n",
    "            count+=1\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy100))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})       \n",
    "            \n",
    "    count = 0        \n",
    "    # 100% Noise\n",
    "    for i in range(2200):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        #shuffle_rows(batch[1], [0,50])\n",
    "        if i % 100 == 0:\n",
    "            test_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('test accuracy %g' % test_accuracy)\n",
    "            arrTest100[count] = test_accuracy\n",
    "            count+=1 \n",
    "    sess.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training and testing accuracy on different noise levels(10%, 25%, 50%, 75%, 100%)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = (arrTrain10.T[0][21], arrTrain25.T[0][21], arrTrain50.T[0][21], arrTrain75.T[0][21], arrTrain100.T[0][21])\n",
    "test = (np.mean(arrTest10.T[0]), np.mean(arrTest25.T[0]), np.mean(arrTest50.T[0]), np.mean(arrTest75.T[0]), np.mean(arrTest100.T[0]))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( (10 , 25 , 50 , 75, 100),dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    #ax.set_xticks(0,100)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('% Noise')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('small')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Training and testing accuracy on different noise levels', fontsize=20)\n",
    "\n",
    "plotter( ax, train,'Blue', 'Train accuracy' )\n",
    "plotter( ax, test, 'Red' , 'Test Accuracy')\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of training accuracy of all 5 models(10%, 25%, 50%, 75%, 100%)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel('Training Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('small')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Training Evaluation on Diff Noise', fontsize=20)\n",
    "\n",
    "plotter( ax, arrTrain10.T[0] ,'Blue', '10% Noise' )\n",
    "plotter( ax,arrTrain25.T[0], 'Red' , '25% Noise')\n",
    "plotter( ax,arrTrain50.T[0], 'Green', '50% Noise' )\n",
    "plotter( ax,arrTrain75.T[0], 'Yellow', '75% Noise' )\n",
    "plotter( ax,arrTrain100.T[0], 'Black', '100% Noise' )\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of testing accuracy of all 5 models(10%, 25%, 50%, 75%, 100%)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel('Testing Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Testing Evaluation on Diff Noise', fontsize=20)\n",
    "\n",
    "\n",
    "plotter( ax, arrTest10.T[0] ,'Blue', '10% Noise' )\n",
    "plotter( ax,arrTest25.T[0], 'Red' , '25% Noise' )\n",
    "plotter( ax,arrTest50.T[0], 'Green' , '50% Noise')\n",
    "plotter( ax,arrTest75.T[0], 'Yellow' , '75% Noise')\n",
    "plotter( ax,arrTest100.T[0], 'Black' , '100% Noise')\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of model with 10% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.5, 0.5])\n",
    "fig.suptitle('Evaluation on 10% Noise', fontsize=20)\n",
    "\n",
    "plotter( ax, arrTrain10.T[0] ,'Blue', '10% Noise Train' )\n",
    "plotter( ax,arrTest10.T[0], 'Red' , '10% Noise Test' )\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of model with 25% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Evaluation on 25% Noise', fontsize=20)\n",
    "\n",
    "plotter(ax, arrTrain25.T[0] ,'Blue', '25% Noise Train' )\n",
    "plotter(ax,arrTest25.T[0], 'Red' , '25% Noise Test' )\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of model with 50% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel(' Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Evaluation on 50% Noise', fontsize=20)\n",
    "\n",
    "\n",
    "plotter( ax, arrTrain50.T[0] ,'Blue', '50% Noise Train' )\n",
    "plotter( ax,arrTest50.T[0], 'Red' , '50% Noise Test' )\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of model with 75% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel(' Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Evaluation on 75% Noise', fontsize=20)\n",
    "\n",
    "plotter( ax, arrTrain75.T[0] ,'Blue', '75% Noise Train' )\n",
    "plotter( ax,arrTest75.T[0], 'Red' , '75% Noise Test' )\n",
    "fig.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of model with 100% Noise</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ans :- We see that the training and the testing accuracies after applying 100% noise are quite similar hence there is not much difference between the\n",
    "errors between them. Moreover the performance of our model trained with 100% noise degrades dramatically.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plotter ( ax,dt, col, lb ):\n",
    "    data = np.random.normal( size=(50, 2 ) )\n",
    "    x, y = [1,2,3], data[:, 1 ]\n",
    "    ax.plot( dt, color=col, label = lb )\n",
    "    ax.set_yticks(np.arange(0.0, 1.15, 0.1))\n",
    "    ax.set_ylabel(' Accuracy')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    legend = ax.legend(loc='upper right', shadow=True, prop={'size':1.5})\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('0.90')\n",
    "\n",
    "    # Set the fontsize\n",
    "    for label in legend.get_texts():\n",
    "        label.set_fontsize('large')\n",
    "\n",
    "    for label in legend.get_lines():\n",
    "        label.set_linewidth(1.5)  # the legend line width\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, 0.7, 0.7])\n",
    "fig.suptitle('Evaluation on 100% Noise', fontsize=20)\n",
    "\n",
    "plotter( ax, arrTrain100.T[0] ,'Blue', '100% Noise Train' )\n",
    "plotter( ax,arrTest100.T[0], 'Red' , '100% Noise Test' )\n",
    "fig.show( )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
