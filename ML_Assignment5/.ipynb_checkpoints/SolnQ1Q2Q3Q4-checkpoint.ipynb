{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q1 Implement a multi-layer perceptron (MLP) by modifying the MLP program\n",
    "from the class to solve the XOR problem and train it to translate the digital letters given in file pattern1 into\n",
    "the corresponding ASCII representation. Plot a training curve and interpret your results.</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 96.15384615384616 %\n",
      "ASCII values of the data are as follows :- [65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 71 88 89\n",
      " 90]\n"
     ]
    }
   ],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data are as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Q2 Investigate how much noise the MLP can tolerate in the pattern before\n",
    "being unable to recognize a letter. Report your results.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1 % Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(2):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 1% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3% Noise Case</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(5):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>6 % Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(9):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 6% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>10% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(15):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>20% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(31):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>30% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(49):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>50% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(78):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<b>70% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(109):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>100% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        for j in range(156):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 3% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "out = (float(i) for i in error)\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q3 Which letter is represented in file pattern2?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 1 1]\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "\n",
    "\n",
    "# Convert the Numbers into 0 and 1\n",
    "X = np.genfromtxt('pattern2', dtype = float, delimiter='  ')\n",
    "\n",
    "X= X[0 : 12, :].flatten().T\n",
    "\n",
    "h=1/(1+exp(-wh@X))\n",
    "y=1/(1+exp(-wo@h)).T   \n",
    "y = 1*(y>0.5)\n",
    "print(y)\n",
    "print(int(''.join(str(item) for item in y), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Ans :- Hence our model gives us a different character for this pattern everytime we run.</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q4 Investigate the network performance when training on noisy patterns. Also,\n",
    "how the number of hidden nodes influence the performance?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Taking 3 nodes in Hidden layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 3 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data is as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Taking 7 nodes in Hidden layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 7 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data is as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<b>Taking 12 nodes in Hidden layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 12 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data is as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<b>Taking 16 nodes in Hidden layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data is as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<b>Taking 20 nodes in Hidden layer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 20 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "predictions = [int(row, 2) for row in BinToDec]\n",
    "predictions = np.array(predictions, dtype = int)\n",
    "total = 26.0\n",
    "score = 0\n",
    "for i in range(26) :\n",
    "    if(actualValues[i] == predictions[i]):\n",
    "        score+= 1\n",
    "print('Accuracy is ' +str((score/total)*100) + ' %')\n",
    "print('ASCII values of the data is as follows :- '+ str(predictions))\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>\n",
    "Accuracy Results for different models with different number of nodes in a hidden layer\n",
    "<n></n>\n",
    "3 Nodes :- 11.53%\n",
    "<n></n>\n",
    "7 Nodes :- 19.23%\n",
    "<n></n>\n",
    "12 Nodes :- 84.61%\n",
    "<n></n>\n",
    "16 Nodes :- 96.16%  = Best Model\n",
    "<n></n>\n",
    "20 Nodes :- 100%\n",
    "</b>\n",
    "\n",
    "Though with 20 nodes we get 100 % accuracy but it tends to overfit the data. So we select the model with 16 Nodes as our model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training the model with 10% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy after 100 runs of adding 1% noise to all the characters is 34.6153846154 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8845cad62be5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'WebAgg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mShowBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mTk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;34m\"\"\"Run the main loop of Tcl.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0m_default_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[0mgetint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "    for j in range(17):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        \n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 1% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<b>Training the model with 50% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy after 100 runs of adding 50% noise to all the characters is 3.84615384615 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-83b77ff4c48d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'WebAgg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mShowBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mTk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;34m\"\"\"Run the main loop of Tcl.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0m_default_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[0mgetint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "    for j in range(62):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        \n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 50% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Training the model with 90% Noise>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training the model with 90% Noise</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy after 100 runs of adding 90% noise to all the characters is 7.69230769231 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2e7b5e41ee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \"\"\"\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'WebAgg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mShowBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mTk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mshow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vishnu/anaconda3/lib/python3.5/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;34m\"\"\"Run the main loop of Tcl.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0m_default_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[0mgetint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MLP with backpropagation learning of AND function\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# training vectors (Boolean AND function and constant input)\n",
    "data = np.genfromtxt('pattern1', dtype = float, delimiter=' ')\n",
    "InputData = np.ndarray((26,156), dtype = int)\n",
    "\n",
    "for i in range(26):\n",
    "    InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "    for j in range(140):\n",
    "            value = randint(0, 156)\n",
    "            if(InputData[i,value]==1):\n",
    "                InputData[i,value] = 0\n",
    "            elif(InputData[i,value]==0):\n",
    "                InputData[i,value] = 1\n",
    "\n",
    "\n",
    "X = InputData.T\n",
    "Y = np.array([list('{0:08b}'.format(x)) for x in range(65,91)], dtype = float)\n",
    "actualValues = np.array(range(65,91))\n",
    "\n",
    "\n",
    "# model specifications\n",
    "Ni = 156\n",
    "Nh = 16 # This is for 1 layer\n",
    "No = 8\n",
    "\n",
    "Ntrials = 2000\n",
    "\n",
    "h=zeros(Nh)\n",
    "y=zeros(No) # This will be a 8 value vector\n",
    "\n",
    "wh=randn(Nh,Ni) # For 1 layer (16,156) \n",
    "wo=randn(No,Nh) \n",
    "\n",
    "dwh=zeros(wh.shape)\n",
    "dwo=zeros(wo.shape) \n",
    "\n",
    "dh=zeros(Nh)\n",
    "do=zeros(No)  \n",
    "\n",
    "error=zeros(Ntrials)\n",
    "\n",
    "for trial in range(Ntrials):     \n",
    "    #randomly pick training example\n",
    "    pat = randint(26)\n",
    "    x=X[:,pat]\n",
    "    \n",
    "    #calculate prediction    \n",
    "    h=1/(1+exp(-np.dot(wh,x))) #Output for your first hidden layer\n",
    "    #y= 1*((1/(1+exp(-np.dot(wo,h))))>0.5)\n",
    "    y= 1/(1+exp(-np.dot(wo,h)))\n",
    "    \n",
    "    # delta term for each layer (objective function error)   \n",
    "    do=y*(1-y)*(Y[pat] - y)   \n",
    "    dh=(h*(1-h))*(wo.transpose()@do)    \n",
    "    \n",
    "    # update weights with momentum\n",
    "    dwo=0.9*dwo+outer(h,do).T\n",
    "    wo=wo+0.1*dwo\n",
    "    dwh=0.9*dwh+outer(dh,x)\n",
    "    wh=wh+0.1*dwh\n",
    "    \n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    error[trial]=error[trial]+sum(abs(y - Y))\n",
    "\n",
    "acc = zeros(100)\n",
    "error=zeros(100)\n",
    "\n",
    "for iterr in range(100):\n",
    "    for i in range(26):\n",
    "        InputData[i] = data[12*i : 12*(i+1), :].flatten()\n",
    "        # Add some noise here \n",
    "        \n",
    "    X = InputData.T\n",
    "    # test all pattern    \n",
    "    h=1/(1+exp(-wh@X))\n",
    "    y=1/(1+exp(-wo@h)).T   \n",
    "    y = 1*(y>0.5)\n",
    "    BinToDec = ((''.join([str(item) for item in data])) for data in y)\n",
    "    predictions = [int(row, 2) for row in BinToDec]\n",
    "    predictions = np.array(predictions, dtype = int)\n",
    "    error[iterr]=error[iterr]+sum(abs(y - Y))\n",
    "\n",
    "    total = 26.0\n",
    "    score = 0\n",
    "    for i in range(26) :\n",
    "        if(actualValues[i] == predictions[i]):\n",
    "            score+= 1\n",
    "    acc[iterr] = score/total\n",
    "print('Mean Accuracy after 100 runs of adding 90% noise to all the characters is ' +str(np.mean(acc)*100) + ' %')\n",
    "plt.plot(error)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>So as we increase the noise and keep training our model, till 50 % noise our accuracy decreases to 4% but after that there is no significant change in the accuracy. And on the contrary we find a minor increase in accuracy which can be because the flipping is nullified.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
